{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import regex as re\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import networkx as nx\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(filepath:str='cache.json')->dict:\n",
    "    '''Opens a file'''\n",
    "    cache_file = open(filepath, 'r')\n",
    "    cache_contents = cache_file.read()\n",
    "    artist_data = json.loads(cache_contents)\n",
    "    cache_file.close()\n",
    "    return artist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_full_network(playlist_link:str,random_link:str,cache_file:str)->nx.Graph:\n",
    "    playlist_network = open_file(playlist_link)\n",
    "    random_network = open_file(random_link)\n",
    "    cache = open_file(cache_file)\n",
    "    # combine!!\n",
    "\n",
    "    # playlist network doesn't have name key, my bad\n",
    "    for artist in playlist_network.keys():\n",
    "        playlist_network[artist]['name']=artist\n",
    "\n",
    "    g = nx.Graph()\n",
    "    for artist in playlist_network.keys():\n",
    "        g.add_node(artist)\n",
    "        colab = playlist_network[artist]['collaborators'].keys()\n",
    "        for y in colab:\n",
    "            if artist !=y:\n",
    "                if y not in g.nodes:\n",
    "                    g.add_node(y)\n",
    "                g.add_edge(artist,y)\n",
    "\n",
    "    for n in g.nodes():\n",
    "        g.nodes[n]['source'] = 'playlist'\n",
    "        if n in playlist_network.keys():\n",
    "            for key in playlist_network[n].keys():\n",
    "                g.nodes[n][key]= playlist_network[n][key]\n",
    "        else:\n",
    "            for key in cache[n].keys():\n",
    "                g.nodes[n][key]=cache[n][key]\n",
    "            g.nodes[n]['in_playlist']=False\n",
    "            g.nodes[n]['name']=n\n",
    "\n",
    "\n",
    "    for artist in random_network.keys():\n",
    "        if artist not in g.nodes:\n",
    "            g.add_node(artist)\n",
    "            g.nodes[artist]['source']='random'\n",
    "        colab = random_network[artist]['collaborators'].keys()\n",
    "        for y in colab:\n",
    "            if artist !=y:\n",
    "                if y not in g.nodes:\n",
    "                    g.add_node(y)\n",
    "                g.add_edge(artist,y)\n",
    "                g.nodes[y]['source']='random'\n",
    "\n",
    "    for n in g.nodes():\n",
    "        if n in random_network.keys():\n",
    "            for key in random_network[n].keys():\n",
    "                g.nodes[n][key]= random_network[n][key]\n",
    "            g.nodes[n]['in_playlist']=False\n",
    "            g.nodes[n]['name']=n\n",
    "            if n not in playlist_network.keys():\n",
    "                for key in cache[n].keys():\n",
    "                    g.nodes[n][key]=cache[n][key]\n",
    "            g.nodes[n]['source']='random'\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading complete networks\n",
    "week1_g = load_full_network('10_26_playlist_layer2.json','10_26_random_2layer.json','cache.json')\n",
    "week2_g = load_full_network('11_01_playlist_layer2.json','10_26_random_2layer.json','cache.json')\n",
    "week3_g = load_full_network('11_08_playlist_layer2.json','10_26_random_2layer.json','cache.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to gather the info about the different networks and see how they change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['source', 'genres', 'img_info', 'popularity', 'followers',\n",
      "       'collaborators', 'in_playlist', 'link', 'name', 'api_link'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# make dataframe with networks attributes\n",
    "week1_df =pd.DataFrame.from_dict(dict(week1_g.nodes(data=True)), orient='index')\n",
    "week2_df =pd.DataFrame.from_dict(dict(week2_g.nodes(data=True)), orient='index')\n",
    "week3_df =pd.DataFrame.from_dict(dict(week3_g.nodes(data=True)), orient='index')\n",
    "# print the columns\n",
    "print(week1_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making an easy way to iterate\n",
    "graphs = {'week1': {'graph':week1_g, 'df':week1_df},\n",
    "          'week2': {'graph':week2_g, 'df':week2_df},\n",
    "          'week3': {'graph':week3_g, 'df':week3_df},}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for week in graphs.keys():\n",
    "    # set graph & df\n",
    "    g, df = graphs[week]['graph'], graphs[week]['df']\n",
    "    # get pagerank\n",
    "    pr = nx.pagerank(g)\n",
    "    df['pagerank']=df['name'].apply(lambda x: pr[x])\n",
    "    # get closeness centrality\n",
    "    # cc = nx.closeness_centrality(g)\n",
    "    # df['closeness_cent']=df['name'].apply(lambda x: cc[x])\n",
    "    # clustering\n",
    "    clust = nx.clustering(g)\n",
    "    df['clustering']=df['name'].apply(lambda x: clust[x])\n",
    "    # degree centrality\n",
    "    deg_cent = nx.degree_centrality(g)\n",
    "    df['deg_cent']=df['name'].apply(lambda x: deg_cent[x])\n",
    "    # betweenness centrality\n",
    "    # btwn_centr = nx.betweenness_centrality(g)\n",
    "    # df['btwn_centr']=df['name'].apply(lambda x: btwn_centr[x])\n",
    "    # degree\n",
    "    deg = nx.degree(g)\n",
    "    df['degree']=df['name'].apply(lambda x: deg[x])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_nodes = [x for x in week1_g.nodes if week1_g.nodes[x]['source']=='playlist'] #if week1_g.nodes[x]['source']=='playlist'\n",
    "random_nodes = [x for x in week1_g.nodes if week1_g.nodes[x]['source']=='random']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hanumankind\n"
     ]
    }
   ],
   "source": [
    "for x in week1_g.nodes:\n",
    "    print(x)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si649f23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
